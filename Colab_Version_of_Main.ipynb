{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmMmfCYWfmjx"
      },
      "source": [
        "## Honest-but-Curious Nets (ACM CCS'21)\n",
        "\n",
        "https://github.com/mmalekzadeh/honest-but-curious-nets\n",
        "\n",
        "This notebook is prepared for those who want to run an expermints on Google Colab GPUs.\n",
        "> The result is the same as running `main.py` on your machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EkjjP5DUfIx",
        "outputId": "69c44cfb-2145-4b67-b1fa-1e63d46c254a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount= True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMxA_muqgdjp"
      },
      "source": [
        "I assume that you have copied the [GitHub Folder](https://github.com/mmalekzadeh/honest-but-curious-nets) in your Google drive. So, we just open the directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pneovht-WyG8",
        "outputId": "867734cb-94ef-470c-ffcf-626882176954"
      },
      "source": [
        "cd gdrive/My\\ Drive/honest-but-curious-nets"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/honest-but-curious-nets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bepPP8kyXD7B"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\".\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyOSZAk2XGr3"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, TensorDataset\n",
        "from torchsummary import summary\n",
        "import copy\n",
        "import torchvision \n",
        "##\n",
        "from hbcnets import datasets, models, utils, trainers, constants\n",
        "## Optional: For making your results reproducible\n",
        "torch.manual_seed(constants.RANDOM_SEED)\n",
        "torch.cuda.manual_seed(constants.RANDOM_SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(constants.RANDOM_SEED)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuNQWcyOhJBH"
      },
      "source": [
        "Here I copied the file `setting.py` in a way that I can pass the desired `args` to the `main(args)` method.\n",
        "> This will do the same thing as we do with `from setting import args_parser`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuuxVsDHXfWv"
      },
      "source": [
        "import argparse\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "## Training parameters\n",
        "parser.add_argument('--server_epochs', type=int, default=20,\n",
        "                    help=\"Number of Epochs\")    \n",
        "parser.add_argument('--server_batch', type=int, default=100,\n",
        "                    help=\"Batch Size\")\n",
        "parser.add_argument('--server_lr', type=int, default=0.001,\n",
        "                    help=\"Learning Rate\")                                                    \n",
        "\n",
        "## Attack Type\n",
        "parser.add_argument('--attack', type=str, default=\"parameterized\",\n",
        "                    help=\"either 'parameterized' or 'regularized'\")  \n",
        "\n",
        "## Etc.\n",
        "parser.add_argument('--root_dir', type=str, default=\"hbcnets\",\n",
        "                    help=\"The root directory for saving data and results.\")    \n",
        "parser.add_argument('--gpu', default=0, \n",
        "                    help=\"When using GPU, set --gpu=0\")\n",
        "parser.add_argument('--device', default='cuda', \n",
        "                    help=\"When using GPU, set --device='cuda'\")\n",
        "\n",
        "args = parser.parse_args([])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhA6hZK_h6uW"
      },
      "source": [
        "The below is exactly the `main.py`, but as a method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT8fkQCzYd3k"
      },
      "source": [
        "# if __name__ == '__main__':\n",
        "def main(args):\n",
        "        \n",
        "    # args = args_parser() ## Reading the input arguments (see setting.py)\n",
        "    if args.gpu:\n",
        "        torch.cuda.set_device(args.gpu)\n",
        "    ## Fetch the datasets\n",
        "    if constants.DATASET == \"utk_face\":\n",
        "        (train_images, train_labels), (test_images, test_labels) = datasets.get_dataset(args)     \n",
        "        train_labels, test_labels = datasets.prepare_labels(train_labels, test_labels)  \n",
        "        train_labels = train_labels[:,[constants.HONEST,constants.CURIOUS]].astype(int)\n",
        "        test_labels  =  test_labels[:,[constants.HONEST,constants.CURIOUS]].astype(int)\n",
        "        train_dataset = (train_images, train_labels)    \n",
        "    elif constants.DATASET == \"celeba\":\n",
        "        (train_images, train_labels), (valid_images, valid_labels), (test_images, test_labels) = datasets.get_dataset(args)\n",
        "        train_labels, valid_labels, test_labels = datasets.prepare_labels(train_labels, test_labels, valid_labels)\n",
        "        train_dataset = ((train_images, train_labels), (valid_images, valid_labels))    \n",
        "\n",
        "    print(\"\\n*** Dataset's Info\") \n",
        "    print(\"Training\")\n",
        "    utils.print_dataset_info((train_images, train_labels))\n",
        "    if constants.DATASET == \"celeba\":\n",
        "        print(\"Validation\")\n",
        "        utils.print_dataset_info((valid_images, valid_labels))\n",
        "    print(\"Testing\")\n",
        "    utils.print_dataset_info((test_images, test_labels))                    \n",
        "      \n",
        "\n",
        "    ## For logging\n",
        "    exp_name = str(constants.HONEST)+\"_\"+str(constants.CURIOUS)+\"_\"+str(constants.K_Y)+\\\n",
        "                \"_\"+str(constants.K_S)+\"_\"+str(int(constants.BETA_X))+\"_\"+str(int(constants.BETA_Y))+\\\n",
        "                \"_\"+str(constants.SOFTMAX)+\"/\"+str(constants.IMAGE_SIZE)+\"_\"+str(constants.RANDOM_SEED) \n",
        "\n",
        "    ## Model\n",
        "    model = models.Classifier(num_classes=constants.K_Y, with_softmax=constants.SOFTMAX)        \n",
        "    model.to(args.device)\n",
        "    summary(model, input_size=(3, constants.IMAGE_SIZE, constants.IMAGE_SIZE),device=args.device)            \n",
        "                 \n",
        "    if args.attack == \"parameterized\":\n",
        "        param_G = models.Parameterized(num_inputs=constants.K_Y, num_classes=constants.K_S)        \n",
        "        param_G.to(args.device)\n",
        "        summary(param_G, input_size=(constants.K_Y,), device=args.device)       \n",
        "\n",
        "        save_dir = args.root_dir+\"/results_par/\"+constants.DATASET+\"/\"+exp_name+\"/\"\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.makedirs(save_dir)            \n",
        "        model, param_G = trainers.train_model_par(args, model, param_G, train_dataset, save_dir)  \n",
        "\n",
        "        ## Test    \n",
        "        model.load_state_dict(torch.load(save_dir+\"best_model.pt\", map_location=torch.device(args.device)))         \n",
        "        param_G.load_state_dict(torch.load(save_dir+\"best_param_G.pt\", map_location=torch.device(args.device)))         \n",
        "        test_data_loader = DataLoader(TensorDataset(torch.Tensor(test_images), torch.Tensor(test_labels).long()),\n",
        "                                batch_size=len(test_images)//50, shuffle=False, drop_last=False)  \n",
        "        eval_acc_1, eval_acc_2, cf_mat_1, cf_mat_2  = utils.evaluate_acc_par(args, model, param_G, test_data_loader, cf_mat=True, roc=False)\n",
        "        print(\"\\n$$$ Test Accuracy of the BEST model Y {:.2f}\".format(eval_acc_1))\n",
        "        print(\"     Confusion Matrix Y:\\n\", (cf_mat_1*100).round(2))    \n",
        "        print(\"\\n$$$ Test Accuracy of the BEST model S {:.2f}\".format(eval_acc_2))\n",
        "        print(\"     Confusion Matrix S:\\n\", (cf_mat_2*100).round(2))\n",
        "\n",
        "        ### Optional: to report the avg entropy\n",
        "        yh = utils.evaluate_acc_par(args, model, param_G, test_data_loader, preds=True)\n",
        "        yh = torch.tensor(yh)\n",
        "        yh_entropies = (-torch.sum(yh * torch.log2(yh), dim=1))\n",
        "        norm_ent = torch.linalg.norm(yh_entropies, ord=1)/len(yh_entropies)\n",
        "        print(\"\\n$$$ The average of the entropy of classifiers output {:.4f}\".format(norm_ent))    \n",
        "    \n",
        "    elif args.attack == \"regularized\":\n",
        "        save_dir = args.root_dir+\"/results_reg/\"+constants.DATASET+\"/\"+exp_name+\"/\"\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.makedirs(save_dir)            \n",
        "        model = trainers.train_model_reg(args, model, \n",
        "                        train_dataset, save_dir)  \n",
        "\n",
        "        ## Valid   \n",
        "        best_REGTAU = 0.\n",
        "        best_acc_valid = 0.\n",
        "        model.load_state_dict(torch.load(save_dir+\"best_model.pt\", map_location=torch.device(args.device)))             \n",
        "        for REGTAU in np.arange(.04,.91,.02):        \n",
        "            valid_data_loader =  trainers.get_data_loader(args, train_dataset, train=False)\n",
        "            eval_acc_1, eval_acc_2  = utils.evaluate_acc_reg(args, model, valid_data_loader,\n",
        "                                                                                    beTau=REGTAU)    \n",
        "            if eval_acc_2 > best_acc_valid:\n",
        "                best_REGTAU = REGTAU\n",
        "                best_acc_valid = eval_acc_2            \n",
        "        print(\"\\n$$$ Tau {} Valid Acc G , {:.2f}\".format(best_REGTAU, best_acc_valid))  \n",
        "        ## Test\n",
        "        test_data_loader = DataLoader(TensorDataset(torch.Tensor(test_images), torch.Tensor(test_labels).long()),\n",
        "                                batch_size=len(test_images)//50, shuffle=False, drop_last=False)  \n",
        "        eval_acc_1, eval_acc_2, cf_mat_1, cf_mat_2  = utils.evaluate_acc_reg(args, model, test_data_loader, cf_mat=True, roc=False, \n",
        "                                                                                    beTau=best_REGTAU)\n",
        "        print(\"\\n$$$ Test Accuracy of the BEST model Y {:.2f}\".format(eval_acc_1))\n",
        "        print(\"     Confusion Matrix Y:\\n\", (cf_mat_1*100).round(2))    \n",
        "        print(\"\\n$$$ Test Accuracy of the BEST model S {:.2f}\".format(eval_acc_2))\n",
        "        print(\"     Confusion Matrix S:\\n\", (cf_mat_2*100).round(2))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PphADhsjiCVd"
      },
      "source": [
        "Before running the final command, make sure that you have set up your desired experiment in the `hbcnets/constants.py`. e.g., This note book is for Age vs. Race (both 3-class) on UTKFace dataset.\n",
        "> That's it :-) Hope you enjoy it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZcjP6W_YeM3",
        "outputId": "13214bbb-efae-430c-82d0-a34ebe8cc781"
      },
      "source": [
        "main(args)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*** Dataset's Info\n",
            "Training\n",
            "Data Dimensions:  (18964, 3, 64, 64)\n",
            "Honest:\n",
            " [[   0 8213]\n",
            " [   1 6883]\n",
            " [   2 3868]]\n",
            "Curious:\n",
            " [[   0 8002]\n",
            " [   1 8196]\n",
            " [   2 2766]]\n",
            "Testing\n",
            "Data Dimensions:  (4741, 3, 64, 64)\n",
            "Honest:\n",
            " [[   0 2017]\n",
            " [   1 1715]\n",
            " [   2 1009]]\n",
            "Curious:\n",
            " [[   0 2076]\n",
            " [   1 1997]\n",
            " [   2  668]]\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 128, 32, 32]           1,664\n",
            "       BatchNorm2d-2          [-1, 128, 32, 32]             256\n",
            "         LeakyReLU-3          [-1, 128, 32, 32]               0\n",
            "           Dropout-4          [-1, 128, 32, 32]               0\n",
            "            Conv2d-5          [-1, 128, 16, 16]          65,664\n",
            "       BatchNorm2d-6          [-1, 128, 16, 16]             256\n",
            "         LeakyReLU-7          [-1, 128, 16, 16]               0\n",
            "           Dropout-8          [-1, 128, 16, 16]               0\n",
            "            Conv2d-9             [-1, 64, 8, 8]          32,832\n",
            "      BatchNorm2d-10             [-1, 64, 8, 8]             128\n",
            "        LeakyReLU-11             [-1, 64, 8, 8]               0\n",
            "          Dropout-12             [-1, 64, 8, 8]               0\n",
            "           Conv2d-13             [-1, 64, 4, 4]          16,448\n",
            "      BatchNorm2d-14             [-1, 64, 4, 4]             128\n",
            "        LeakyReLU-15             [-1, 64, 4, 4]               0\n",
            "          Dropout-16             [-1, 64, 4, 4]               0\n",
            "           Linear-17                  [-1, 128]         131,200\n",
            "        LeakyReLU-18                  [-1, 128]               0\n",
            "          Dropout-19                  [-1, 128]               0\n",
            "           Linear-20                    [-1, 3]             387\n",
            "================================================================\n",
            "Total params: 248,963\n",
            "Trainable params: 248,963\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 5.16\n",
            "Params size (MB): 0.95\n",
            "Estimated Total Size (MB): 6.16\n",
            "----------------------------------------------------------------\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                   [-1, 60]             240\n",
            "         LeakyReLU-2                   [-1, 60]               0\n",
            "           Dropout-3                   [-1, 60]               0\n",
            "            Linear-4                   [-1, 30]           1,830\n",
            "         LeakyReLU-5                   [-1, 30]               0\n",
            "           Dropout-6                   [-1, 30]               0\n",
            "            Linear-7                    [-1, 3]              93\n",
            "================================================================\n",
            "Total params: 2,163\n",
            "Trainable params: 2,163\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.01\n",
            "Estimated Total Size (MB): 0.01\n",
            "----------------------------------------------------------------\n",
            "_________ Epoch:  1\n",
            "**** Best Weighted Valid Acc Y & S on Epoch 1 is 69.38\n",
            "- Train Loss Y: 0.82606, \n",
            "- Train Acc Y: 61.98\n",
            "- Valid Acc Y: 72.31\n",
            "- Train Loss S: 0.93010, \n",
            "- Train Acc S: 53.31\n",
            "- Valid Acc S: 62.55\n",
            "- Train Entropy Loss: 0.73090\n",
            "_________ Epoch:  2\n",
            "**** Best Weighted Valid Acc Y & S on Epoch 2 is 74.05\n",
            "- Train Loss Y: 0.66254, \n",
            "- Train Acc Y: 72.14\n",
            "- Valid Acc Y: 75.95\n",
            "- Train Loss S: 0.81946, \n",
            "- Train Acc S: 62.63\n",
            "- Valid Acc S: 69.62\n",
            "- Train Entropy Loss: 0.56010\n",
            "_________ Epoch:  3\n",
            "- Train Loss Y: 0.61831, \n",
            "- Train Acc Y: 74.12\n",
            "- Valid Acc Y: 74.79\n",
            "- Train Loss S: 0.73206, \n",
            "- Train Acc S: 67.79\n",
            "- Valid Acc S: 72.10\n",
            "- Train Entropy Loss: 0.51521\n",
            "_________ Epoch:  4\n",
            "**** Best Weighted Valid Acc Y & S on Epoch 4 is 77.36\n",
            "- Train Loss Y: 0.58355, \n",
            "- Train Acc Y: 75.80\n",
            "- Valid Acc Y: 78.06\n",
            "- Train Loss S: 0.68051, \n",
            "- Train Acc S: 70.37\n",
            "- Valid Acc S: 75.74\n",
            "- Train Entropy Loss: 0.48698\n",
            "_________ Epoch:  5\n",
            "**** Best Weighted Valid Acc Y & S on Epoch 5 is 78.80\n",
            "- Train Loss Y: 0.56494, \n",
            "- Train Acc Y: 77.26\n",
            "- Valid Acc Y: 79.11\n",
            "- Train Loss S: 0.64174, \n",
            "- Train Acc S: 73.23\n",
            "- Valid Acc S: 78.06\n",
            "- Train Entropy Loss: 0.46937\n",
            "_________ Epoch:  6\n",
            "**** Best Weighted Valid Acc Y & S on Epoch 6 is 78.95\n",
            "- Train Loss Y: 0.54480, \n",
            "- Train Acc Y: 77.91\n",
            "- Valid Acc Y: 78.74\n",
            "- Train Loss S: 0.61406, \n",
            "- Train Acc S: 74.24\n",
            "- Valid Acc S: 79.43\n",
            "- Train Entropy Loss: 0.45251\n",
            "_________ Epoch:  7\n",
            "**** Best Weighted Valid Acc Y & S on Epoch 7 is 79.43\n",
            "- Train Loss Y: 0.52518, \n",
            "- Train Acc Y: 78.82\n",
            "- Valid Acc Y: 79.11\n",
            "- Train Loss S: 0.59793, \n",
            "- Train Acc S: 75.45\n",
            "- Valid Acc S: 80.17\n",
            "- Train Entropy Loss: 0.43645\n",
            "_________ Epoch:  8\n",
            "**** Best Weighted Valid Acc Y & S on Epoch 8 is 79.83\n",
            "- Train Loss Y: 0.51445, \n",
            "- Train Acc Y: 79.24\n",
            "- Valid Acc Y: 78.85\n",
            "- Train Loss S: 0.58090, \n",
            "- Train Acc S: 76.09\n",
            "- Valid Acc S: 82.12\n",
            "- Train Entropy Loss: 0.42731\n",
            "_________ Epoch:  9\n",
            "**** Best Weighted Valid Acc Y & S on Epoch 9 is 80.56\n",
            "- Train Loss Y: 0.50006, \n",
            "- Train Acc Y: 79.75\n",
            "- Valid Acc Y: 80.43\n",
            "- Train Loss S: 0.57198, \n",
            "- Train Acc S: 76.42\n",
            "- Valid Acc S: 80.85\n",
            "- Train Entropy Loss: 0.41783\n",
            "_________ Epoch:  10\n",
            "- Train Loss Y: 0.48826, \n",
            "- Train Acc Y: 80.31\n",
            "- Valid Acc Y: 78.59\n",
            "- Train Loss S: 0.55665, \n",
            "- Train Acc S: 77.09\n",
            "- Valid Acc S: 81.12\n",
            "- Train Entropy Loss: 0.41207\n",
            "_________ Epoch:  11\n",
            "- Train Loss Y: 0.47982, \n",
            "- Train Acc Y: 80.76\n",
            "- Valid Acc Y: 79.91\n",
            "- Train Loss S: 0.54942, \n",
            "- Train Acc S: 77.82\n",
            "- Valid Acc S: 81.86\n",
            "- Train Entropy Loss: 0.40558\n",
            "_________ Epoch:  12\n",
            "**** Best Weighted Valid Acc Y & S on Epoch 12 is 80.76\n",
            "- Train Loss Y: 0.47644, \n",
            "- Train Acc Y: 80.76\n",
            "- Valid Acc Y: 80.27\n",
            "- Train Loss S: 0.54125, \n",
            "- Train Acc S: 78.49\n",
            "- Valid Acc S: 81.91\n",
            "- Train Entropy Loss: 0.39632\n",
            "_________ Epoch:  13\n",
            "**** Best Weighted Valid Acc Y & S on Epoch 13 is 80.77\n",
            "- Train Loss Y: 0.45921, \n",
            "- Train Acc Y: 81.70\n",
            "- Valid Acc Y: 80.49\n",
            "- Train Loss S: 0.54169, \n",
            "- Train Acc S: 78.45\n",
            "- Valid Acc S: 81.43\n",
            "- Train Entropy Loss: 0.39216\n",
            "_________ Epoch:  14\n",
            "**** Best Weighted Valid Acc Y & S on Epoch 14 is 81.50\n",
            "- Train Loss Y: 0.46567, \n",
            "- Train Acc Y: 81.35\n",
            "- Valid Acc Y: 80.70\n",
            "- Train Loss S: 0.53188, \n",
            "- Train Acc S: 78.80\n",
            "- Valid Acc S: 83.39\n",
            "- Train Entropy Loss: 0.39927\n",
            "_________ Epoch:  15\n",
            "- Train Loss Y: 0.45105, \n",
            "- Train Acc Y: 81.70\n",
            "- Valid Acc Y: 79.85\n",
            "- Train Loss S: 0.53057, \n",
            "- Train Acc S: 78.76\n",
            "- Valid Acc S: 83.18\n",
            "- Train Entropy Loss: 0.38655\n",
            "_________ Epoch:  16\n",
            "- Train Loss Y: 0.44785, \n",
            "- Train Acc Y: 82.06\n",
            "- Valid Acc Y: 79.96\n",
            "- Train Loss S: 0.53324, \n",
            "- Train Acc S: 78.81\n",
            "- Valid Acc S: 82.96\n",
            "- Train Entropy Loss: 0.38861\n",
            "_________ Epoch:  17\n",
            "**** Best Weighted Valid Acc Y & S on Epoch 17 is 81.78\n",
            "- Train Loss Y: 0.44737, \n",
            "- Train Acc Y: 82.16\n",
            "- Valid Acc Y: 80.91\n",
            "- Train Loss S: 0.52406, \n",
            "- Train Acc S: 79.28\n",
            "- Valid Acc S: 83.81\n",
            "- Train Entropy Loss: 0.39052\n",
            "_________ Epoch:  18\n",
            "- Train Loss Y: 0.44297, \n",
            "- Train Acc Y: 82.24\n",
            "- Valid Acc Y: 80.85\n",
            "- Train Loss S: 0.52726, \n",
            "- Train Acc S: 78.96\n",
            "- Valid Acc S: 83.60\n",
            "- Train Entropy Loss: 0.39179\n",
            "_________ Epoch:  19\n",
            "- Train Loss Y: 0.44588, \n",
            "- Train Acc Y: 82.53\n",
            "- Valid Acc Y: 80.33\n",
            "- Train Loss S: 0.51884, \n",
            "- Train Acc S: 79.44\n",
            "- Valid Acc S: 83.91\n",
            "- Train Entropy Loss: 0.40142\n",
            "_________ Epoch:  20\n",
            "**** Best Weighted Valid Acc Y & S on Epoch 20 is 82.09\n",
            "- Train Loss Y: 0.43686, \n",
            "- Train Acc Y: 82.95\n",
            "- Valid Acc Y: 81.38\n",
            "- Train Loss S: 0.51695, \n",
            "- Train Acc S: 79.71\n",
            "- Valid Acc S: 83.76\n",
            "- Train Entropy Loss: 0.38514\n",
            "\n",
            "$$$ Test Accuracy of the BEST model Y 81.35\n",
            "     Confusion Matrix Y:\n",
            " [[85.37 11.45  3.17]\n",
            " [20.7  78.37  0.93]\n",
            " [19.72  1.88 78.39]]\n",
            "\n",
            "$$$ Test Accuracy of the BEST model S 81.50\n",
            "     Confusion Matrix S:\n",
            " [[79.   18.21  2.79]\n",
            " [11.27 86.13  2.6 ]\n",
            " [ 5.69 18.86 75.45]]\n",
            "\n",
            "$$$ The average of the entropy of classifiers output 0.5559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epu-rBoRbXpK"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}